{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "4fa72714", "cell_type": "markdown", "source": "# \ud83d\udcd8 Full AutoML Analysis for Lightweight Concrete (OPS + Fibers)", "metadata": {}}, {"id": "8888ad61", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n# \ud83d\udce6 Required Libraries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom pycaret.regression import *\nimport shap\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# \ud83d\udcca Load Dataset\ndata = {\n    \"OPS_Replacement(%)\": [20]*6 + [30]*6 + [40]*6 + [50]*6 + [60]*6,\n    \"Fibre\": [\"CO\", \"HE\", \"BA\", \"KE\", \"JU\", \"FX\"] * 5,\n    \"Stress\": [\n        38.0036, 36.0356, 30.7876, 26.7860, 32.7228, 33.3460,\n        33.0836, 37.4296, 28.6556, 27.9340, 25.0476, 27.5240,\n        28.5408, 25.4740, 26.9664, 22.3908, 24.4572, 19.6520,\n        17.8316, 26.8352, 23.6208, 22.7844, 21.1116, 19.8160,\n        23.7028, 24.1620, 19.1600, 22.0300, 21.8168, 20.0948\n    ],\n    \"Split\": [\n        4.4347, 4.2955, 3.9084, 3.5951, 4.0540, 4.1001,\n        4.0807, 4.3944, 3.7437, 3.6868, 3.4533, 3.6542,\n        3.7346, 3.4884, 3.6096, 3.2286, 3.4042, 2.9855,\n        2.8163, 3.5991, 3.3339, 3.2625, 3.1166, 3.0004,\n        3.3408, 3.3795, 2.9404, 3.1973, 3.1787, 3.0257\n    ],\n    \"Flexure\": [\n        4.3153, 4.2021, 3.8841, 3.6229, 4.0043, 4.0422,\n        4.0263, 4.2826, 3.7472, 3.6997, 3.5033, 3.6724,\n        3.7397, 3.5330, 3.6350, 3.3123, 3.4618, 3.1031,\n        2.9559, 3.6262, 3.4021, 3.3413, 3.2163, 3.1161,\n        3.4080, 3.4408, 3.0640, 3.2855, 3.2696, 3.1379\n    ],\n    \"Sorptivity\": [\n        0.14, 0.13, 0.12, 0.11, 0.12, 0.15,\n        0.156, 0.168, 0.144, 0.132, 0.144, 0.18,\n        0.182, 0.169, 0.156, 0.143, 0.156, 0.195,\n        0.196, 0.182, 0.168, 0.154, 0.168, 0.21,\n        0.224, 0.208, 0.192, 0.176, 0.192, 0.24\n    ]\n}\n\ndf = pd.DataFrame(data)\ndf[\"Fibre\"] = LabelEncoder().fit_transform(df[\"Fibre\"])\n\n# \ud83d\udcca Histogram and Distribution Analysis\ndf.hist(figsize=(12, 8), bins=15, grid=False, edgecolor='black')\nplt.suptitle('Histogram Distribution of Inputs and Outputs', fontsize=16)\nplt.tight_layout()\nplt.show()\n\n# \ud83d\udd17 Correlation Matrix\ncorr_matrix = df.corr()\nplt.figure(figsize=(10, 7))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Pearson Correlation Heatmap Between Input Parameters and Outputs')\nplt.show()\n\n# \ud83d\udcd8 Function for AutoML Analysis for Each Target\ndef run_pycaret_pipeline(target):\n    print(f\"\\n======= AutoML for: {target} =======\\n\")\n    s = setup(df, target=target, session_id=123, silent=True, fold=10, verbose=False)\n\n    # Initial Comparison of Models\n    top_models = compare_models(n_select=2, sort='R2')\n    print(f\"Top Models for {target}: {[model.__class__.__name__ for model in top_models]}\")\n\n    # Train and tune models\n    tuned_models = [tune_model(m, search_library='scikit-optimize', search_algorithm='random') for m in top_models]\n    final_models = [finalize_model(tm) for tm in tuned_models]\n\n    # Evaluation Plots\n    for m in tuned_models:\n        plot_model(m, plot='error')\n        plot_model(m, plot='residuals')\n        plot_model(m, plot='learning')\n        plot_model(m, plot='feature')\n\n    # SHAP summary for the best model\n    shap.initjs()\n    explainer = shap.Explainer(final_models[0].predict, df.drop(columns=[target]))\n    shap_values = explainer(df.drop(columns=[target]))\n    shap.summary_plot(shap_values, df.drop(columns=[target]), show=True)\n\n# \ud83d\udd01 Run for All Targets\nfor target in [\"Stress\", \"Split\", \"Flexure\", \"Sorptivity\"]:\n    run_pycaret_pipeline(target)\n", "outputs": []}]}